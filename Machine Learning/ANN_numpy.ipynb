{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "446848d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec1e7b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('C:/Users/bhatt/OneDrive/Desktop/whisper-main/ANN_Data/data1.csv')\n",
    "label = pd.read_csv('C:/Users/bhatt/OneDrive/Desktop/whisper-main/ANN_Data/label1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "19aec4ed",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19994</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19995</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19996</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19997</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19998</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19999 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       3\n",
       "0      2\n",
       "1      2\n",
       "2      3\n",
       "3      3\n",
       "4      3\n",
       "...   ..\n",
       "19994  3\n",
       "19995  1\n",
       "19996  2\n",
       "19997  2\n",
       "19998  0\n",
       "\n",
       "[19999 rows x 1 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4c08bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.values\n",
    "label = label.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12eea179",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19999, 20) (19999, 1)\n"
     ]
    }
   ],
   "source": [
    "print(data.shape, label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bfc933cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4], dtype=int64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "762ace7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_len = np.max(label) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b956a164",
   "metadata": {},
   "outputs": [],
   "source": [
    "onehot_labels = np.eye(vec_len)[label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "695d343d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19999, 1, 5)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onehot_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cff03c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "onehot_labels = onehot_labels.reshape(19999, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "43f4048c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 1., 0.],\n",
       "       ...,\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       [1., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onehot_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6935c2b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "split = 0.8\n",
    "\n",
    "trainData = data[: int(split * data.shape[0]), :]\n",
    "trainlabel = onehot_labels[: int(split * label.shape[0]), :]\n",
    "\n",
    "rem_data = data[int(split * data.shape[0]):, :]\n",
    "rem_label = onehot_labels[int(split * label.shape[0]):, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "809292a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15999, 20) (15999, 5) (4000, 20) (4000, 5)\n"
     ]
    }
   ],
   "source": [
    "print(trainData.shape, trainlabel.shape, rem_data.shape, rem_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "99324e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "testData = rem_data[: int(0.5 * rem_data.shape[0]), :]\n",
    "testlabel = rem_label[: int(0.5 * rem_label.shape[0]), :]\n",
    "validData = rem_data[int(0.5 * rem_data.shape[0]):, :]\n",
    "validlabel = rem_label[int(0.5 * rem_label.shape[0]):, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "30a5d333",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 20) (2000, 20) (2000, 5) (2000, 5)\n"
     ]
    }
   ],
   "source": [
    "print(testData.shape, validData.shape, testlabel.shape, validlabel.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b3f9353d",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_neuron = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cd5c9928",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "b1 = np.zeros(hidden_neuron)\n",
    "b2 = np.zeros(5)\n",
    "print(b1, b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f2035bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "w1 = np.random.normal(0, 1, (20, hidden_neuron))\n",
    "w2 = np.random.normal(0, 1, (hidden_neuron, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c6471bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def activation(data, choice):\n",
    "    if choice == 0:\n",
    "        return np.tanh(data)\n",
    "    else:\n",
    "        numerator = np.exp(data)\n",
    "        return numerator/np.sum(numerator, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d8c7c2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.003"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c90cc66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7163a1bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost_func(pred, label):\n",
    "    return -(label * np.log(pred) + (1 - label) * np.log(1 - pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2dbdd914",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_prop(data):\n",
    "    a0 = data\n",
    "    z1 = np.dot(a0, w1) + b1\n",
    "    a1 = activation(z1, 0)\n",
    "    z2 = np.dot(a1, w2) + b2\n",
    "    a2 = activation(z2, 1)\n",
    "    return a0, z1, a1, z2, a2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4d6fee12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(pred, label, size):\n",
    "    max_data = np.argmax(pred, axis = 1)\n",
    "    max_label = np.argmax(label, axis=1)\n",
    "    compare = np.equal(max_data, max_label)\n",
    "    return (np.sum(compare)/size)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "82883a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d5ac1c50",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cost 44.87674668734429\n",
      "Training accuracy 73.4920932558285\n",
      "Training Cost nan\n",
      "Training accuracy 74.94218388649291\n",
      "Training Cost nan\n",
      "Training accuracy 75.24845302831426\n",
      "Training Cost nan\n",
      "Training accuracy 74.65466591661979\n",
      "Training Cost nan\n",
      "Training accuracy 20.0075004687793\n",
      "Training Cost nan\n",
      "Training accuracy 20.0075004687793\n",
      "Training Cost nan\n",
      "Training accuracy 20.0075004687793\n",
      "Training Cost nan\n",
      "Training accuracy 20.0075004687793\n",
      "Training Cost nan\n",
      "Training accuracy 20.0075004687793\n",
      "Training Cost nan\n",
      "Training accuracy 20.0075004687793\n",
      "Training Cost nan\n",
      "Training accuracy 20.0075004687793\n",
      "Training Cost nan\n",
      "Training accuracy 20.0075004687793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_25444\\1504349205.py:2: RuntimeWarning: divide by zero encountered in log\n",
      "  return -(label * np.log(pred) + (1 - label) * np.log(1 - pred))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_25444\\1504349205.py:2: RuntimeWarning: invalid value encountered in multiply\n",
      "  return -(label * np.log(pred) + (1 - label) * np.log(1 - pred))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\numpy\\core\\fromnumeric.py:86: RuntimeWarning: overflow encountered in reduce\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_25444\\3942751392.py:5: RuntimeWarning: overflow encountered in exp\n",
      "  numerator = np.exp(data)\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_25444\\3942751392.py:6: RuntimeWarning: invalid value encountered in divide\n",
      "  return numerator/np.sum(numerator, axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cost nan\n",
      "Training accuracy 20.0075004687793\n",
      "Training Cost nan\n",
      "Training accuracy 20.0075004687793\n",
      "Training Cost nan\n",
      "Training accuracy 20.0075004687793\n",
      "Training Cost nan\n",
      "Training accuracy 20.0075004687793\n",
      "Training Cost nan\n",
      "Training accuracy 20.0075004687793\n",
      "Training Cost nan\n",
      "Training accuracy 20.0075004687793\n",
      "Training Cost nan\n",
      "Training accuracy 20.0075004687793\n",
      "Training Cost nan\n",
      "Training accuracy 20.0075004687793\n",
      "Training Cost nan\n",
      "Training accuracy 20.0075004687793\n",
      "Training Cost nan\n",
      "Training accuracy 20.0075004687793\n",
      "Training Cost nan\n",
      "Training accuracy 20.0075004687793\n",
      "Training Cost nan\n",
      "Training accuracy 20.0075004687793\n",
      "Training Cost nan\n",
      "Training accuracy 20.0075004687793\n",
      "Training Cost nan\n",
      "Training accuracy 20.0075004687793\n",
      "Training Cost nan\n",
      "Training accuracy 20.0075004687793\n",
      "Training Cost nan\n",
      "Training accuracy 20.0075004687793\n",
      "Training Cost nan\n",
      "Training accuracy 20.0075004687793\n",
      "Training Cost nan\n",
      "Training accuracy 20.0075004687793\n",
      "Training Cost nan\n",
      "Training accuracy 20.0075004687793\n",
      "Training Cost nan\n",
      "Training accuracy 20.0075004687793\n",
      "Training Cost nan\n",
      "Training accuracy 20.0075004687793\n",
      "Training Cost nan\n",
      "Training accuracy 20.0075004687793\n",
      "Training Cost nan\n",
      "Training accuracy 20.0075004687793\n",
      "Training Cost nan\n",
      "Training accuracy 20.0075004687793\n",
      "Training Cost nan\n",
      "Training accuracy 20.0075004687793\n",
      "Training Cost nan\n",
      "Training accuracy 20.0075004687793\n",
      "Training Cost nan\n",
      "Training accuracy 20.0075004687793\n",
      "Training Cost nan\n",
      "Training accuracy 20.0075004687793\n",
      "Training Cost nan\n",
      "Training accuracy 20.0075004687793\n",
      "Training Cost nan\n",
      "Training accuracy 20.0075004687793\n",
      "Training Cost nan\n",
      "Training accuracy 20.0075004687793\n",
      "Training Cost nan\n",
      "Training accuracy 20.0075004687793\n",
      "Training Cost nan\n",
      "Training accuracy 20.0075004687793\n",
      "Training Cost nan\n",
      "Training accuracy 20.0075004687793\n",
      "Training Cost nan\n",
      "Training accuracy 20.0075004687793\n",
      "Training Cost nan\n",
      "Training accuracy 20.0075004687793\n",
      "Training Cost nan\n",
      "Training accuracy 20.0075004687793\n",
      "Training Cost nan\n",
      "Training accuracy 20.0075004687793\n",
      "Training Cost nan\n",
      "Training accuracy 20.0075004687793\n",
      "Training Cost nan\n",
      "Training accuracy 20.0075004687793\n",
      "Training Cost nan\n",
      "Training accuracy 20.0075004687793\n",
      "Training Cost nan\n",
      "Training accuracy 20.0075004687793\n",
      "Training Cost nan\n",
      "Training accuracy 20.0075004687793\n",
      "Training Cost nan\n",
      "Training accuracy 20.0075004687793\n",
      "Training Cost nan\n",
      "Training accuracy 20.0075004687793\n",
      "Training Cost nan\n",
      "Training accuracy 20.0075004687793\n",
      "Training Cost nan\n",
      "Training accuracy 20.0075004687793\n",
      "Training Cost nan\n",
      "Training accuracy 20.0075004687793\n",
      "Training Cost nan\n",
      "Training accuracy 20.0075004687793\n",
      "Training Cost nan\n",
      "Training accuracy 20.0075004687793\n",
      "Training Cost nan\n",
      "Training accuracy 20.0075004687793\n",
      "Training Cost nan\n",
      "Training accuracy 20.0075004687793\n",
      "Training Cost nan\n",
      "Training accuracy 20.0075004687793\n",
      "Training Cost nan\n",
      "Training accuracy 20.0075004687793\n",
      "Training Cost nan\n",
      "Training accuracy 20.0075004687793\n",
      "Training Cost nan\n",
      "Training accuracy 20.0075004687793\n",
      "Training Cost nan\n",
      "Training accuracy 20.0075004687793\n",
      "Training Cost nan\n",
      "Training accuracy 20.0075004687793\n",
      "Training Cost nan\n",
      "Training accuracy 20.0075004687793\n",
      "Training Cost nan\n",
      "Training accuracy 20.0075004687793\n",
      "Training Cost nan\n",
      "Training accuracy 20.0075004687793\n",
      "Training Cost nan\n",
      "Training accuracy 20.0075004687793\n",
      "Training Cost nan\n",
      "Training accuracy 20.0075004687793\n",
      "Training Cost nan\n",
      "Training accuracy 20.0075004687793\n",
      "Training Cost nan\n",
      "Training accuracy 20.0075004687793\n",
      "Training Cost nan\n",
      "Training accuracy 20.0075004687793\n",
      "Training Cost nan\n",
      "Training accuracy 20.0075004687793\n",
      "Training Cost nan\n",
      "Training accuracy 20.0075004687793\n",
      "Training Cost nan\n",
      "Training accuracy 20.0075004687793\n",
      "Training Cost nan\n",
      "Training accuracy 20.0075004687793\n",
      "Training Cost nan\n",
      "Training accuracy 20.0075004687793\n",
      "Training Cost nan\n",
      "Training accuracy 20.0075004687793\n",
      "Training Cost nan\n",
      "Training accuracy 20.0075004687793\n",
      "Training Cost nan\n",
      "Training accuracy 20.0075004687793\n",
      "Training Cost nan\n",
      "Training accuracy 20.0075004687793\n",
      "Training Cost nan\n",
      "Training accuracy 20.0075004687793\n",
      "Training Cost nan\n",
      "Training accuracy 20.0075004687793\n",
      "Training Cost nan\n",
      "Training accuracy 20.0075004687793\n",
      "Training Cost nan\n",
      "Training accuracy 20.0075004687793\n",
      "Training Cost nan\n",
      "Training accuracy 20.0075004687793\n",
      "Training Cost nan\n",
      "Training accuracy 20.0075004687793\n",
      "Training Cost nan\n",
      "Training accuracy 20.0075004687793\n",
      "Training Cost nan\n",
      "Training accuracy 20.0075004687793\n",
      "Training Cost nan\n",
      "Training accuracy 20.0075004687793\n",
      "Training Cost nan\n",
      "Training accuracy 20.0075004687793\n",
      "Training Cost nan\n",
      "Training accuracy 20.0075004687793\n",
      "Training Cost nan\n",
      "Training accuracy 20.0075004687793\n",
      "Training Cost nan\n",
      "Training accuracy 20.0075004687793\n",
      "validation accuracy\n",
      "19.400000000000002\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    for iteration in range(int(len(trainData)/batch)):\n",
    "        a0,z1,a1,z2,a2=forward_prop(trainData[iteration*batch:(iteration+1)*batch,:])\n",
    "        y=a2\n",
    "        labelBatch=trainlabel[iteration*batch:(iteration+1)*batch,:]\n",
    "        del2=(y-labelBatch)\n",
    "        del1=np.dot(del2,w2.T)*(1 - a1**2)\n",
    "        dcdw2=np.dot(a1.T,del2)\n",
    "        dcdw1=np.dot(a0.T,del1)\n",
    "        dcdb1=np.sum(del1,axis=0)\n",
    "        dcdb2=np.sum(del2,axis=0)\n",
    "        w1=w1-alpha*dcdw1\n",
    "        w2=w2-alpha*dcdw2\n",
    "        b2=b2-alpha*dcdb2\n",
    "        b1=b1-alpha*dcdb1\n",
    "    a0,z1,a1,z2,a2=forward_prop(trainData)\n",
    "    print(\"Training Cost\",(np.sum(cost_func(a2,trainlabel)))/16000.0)\n",
    "    print(\"Training accuracy\",accuracy(a2,trainlabel,len(trainlabel)))\n",
    "    \n",
    "va0,vz1,va1,vz2,va2=forward_prop(validData)\n",
    "vOutput=va2\n",
    "accuracy = accuracy(vOutput,validlabel,2000.0)\n",
    "print(\"validation accuracy\")\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ed1ddc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
